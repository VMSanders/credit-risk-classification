{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d403f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cceb6107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file lending_data.csv from the Resources folder into a Pandas DataFrame\n",
    "lending_data_df = pd.read_csv(\"../Starter_Code/Resources/lending_data.csv\")\n",
    "\n",
    "# Preview the dataframe\n",
    "lending_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b934af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the data into labels and features\n",
    "# loan_status will be the labels, all other columns will be features\n",
    "# note: \n",
    "#     loan_status = 0 => the loan is healthy\n",
    "#     loan_status = 1 => the loan is at high risk of defaulting\n",
    "\n",
    "# Pull out the first 7 columns into their own dataframe.\n",
    "features_df = lending_data_df.iloc[:,0:7]\n",
    "\n",
    "# Preview the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b53d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now separate out the labels.\n",
    "labels = lending_data_df[\"loan_status\"]\n",
    "\n",
    "# Preview the labels.\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cde722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the labels. I should only have values 0 and 1.\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5150b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we don't have any surprise extra labels, which is good. \n",
    "# Since we do have quite a bit more healthy loans in our set, \n",
    "# I would think that the model later on will be more inclined to predict new loans as being healthy.\n",
    "\n",
    "# Next step: Split the data into training and testing datasets. Still have to import the train_test_split module.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a837c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "# This should generate 4 groups of data\n",
    "# Assign a random_state of 1 to the function\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features_df,labels,random_state=1,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1321ca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just out of curiosity, check on the size of the training vs testing sets.\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9871a4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ef1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Create a logistic regression model with the original data.\n",
    "# Fit a logistic regression model by using the training data.\n",
    "\n",
    "# We still have to import the logistic regression module.\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f60946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model and assign a random_state parameter of 1 to the model\n",
    "classifier_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the model with our training data\n",
    "classifier_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96505089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914878250103177"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the model's accuracy on the training data. \n",
    "classifier_model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5444ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing data set.\n",
    "predictions = classifier_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d00644b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442676901753825"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model's performance with: balanced accuracy score, confusion matrix, and classification report.\n",
    "# These have already been imported.\n",
    "\n",
    "# First up is the balanced accuracy score. \n",
    "balanced_accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f5de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18679,    80],\n",
       "       [   67,   558]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next is the confusion matrix.\n",
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f0130bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.87      0.89      0.88       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.94      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a6e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1    75036\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our scores are spot on for loans with a loan_status of 0, not so much for high risk loans with status 1.\n",
    "# This is as expected previously.\n",
    "\n",
    "# Part 2: Predict a logistic regression model with resampled training data.\n",
    "# We'll have to use the RandomOverSampler module from the imbalanced-learn library to resample the data. \n",
    "# First, I still have to import the RandomOverSampler module.\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "oversampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "x_oversampled,y_oversampled = oversampler.fit_resample(features_df,labels)\n",
    "\n",
    "# Be sure to confirm that the labels have an equal number of data points.\n",
    "y_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc4a5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And they do! Split that into training and testing sets.\n",
    "x_train_resampled,x_test_resampled,y_train_resampled,y_test_resampled = train_test_split(x_oversampled,y_oversampled,random_state=1,stratify=y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dea9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a new instance of the logistic regression classifier and train it with the resampled data.\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "resampled_classifier_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "classifier_model.fit(x_train_resampled,y_train_resampled)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "predictions_resampled = classifier_model.predict(x_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23819f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945359560744176"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll check the accuracy using the same measures as before.\n",
    "\n",
    "# First up, the balanced accuracy score.\n",
    "balanced_accuracy_score(y_test_resampled,predictions_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b5841ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18668,    91],\n",
       "       [  114, 18645]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now a confusion matrix.\n",
    "confusion_matrix(y_test_resampled,predictions_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caa6e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18759\n",
      "           1       1.00      0.99      0.99     18759\n",
      "\n",
      "    accuracy                           0.99     37518\n",
      "   macro avg       0.99      0.99      0.99     37518\n",
      "weighted avg       0.99      0.99      0.99     37518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And a classification report.\n",
    "print(classification_report(y_test_resampled,predictions_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the whole I'm happier about the precision and recall scores on this version with the resampled data\n",
    "# since it didn't lose much for the healthy loans and went up significantly from 0.88-ish for high risk loans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
